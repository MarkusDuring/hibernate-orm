Design Guide
============
:toc:

== General Design

Ultimately the idea here is to redefine how Hibernate generates and executes SQL.  In general there are 3(*) sources
for Hibernate to generate and execute SQL:

* HQL query
* Criteria query
* Various load "styles":
	** single-id
	** natural-id
	** other unique key
	** multi-id
	** locker

In other words, in versions of Hibernate prior to 6.0 there were multiple sources for generating the SQL and multiple
sources for executing the SQL and processing any results.

The primary goal for 6.0 is to make performance improvements at the JDBC interaction level in the form of optimizing:

* the SQL that gets generated - queries that are smaller which makes them quicker across wire, easier for db to
 	parse and execute.
* optimizing the processing of ResultSets.  This comes down to:
	** positional access to JDBC results - much quicker for most drivers since they tend to hold these values
		in arrays and the positional access is generally direct array access whereas name access generally
		goes through an intermediate Map-style lookup
	** JDBC "columns" (physical or formula):
		*** condensed to a single reference in the generated SQL - multiple "columns" references (specific references of
			a particular bound column in the persister Navigable model).  An example would be an entity that maps more than one
			attribute to a given column; for each of those attributes we wil generate just a single reference
			to that column in the SQL SELECT.  E.g. the PERSON table might have a FIRST_NAME column that the Person
			entity map multiple attributes for some reason.  When we generate the SQL SELECT we understand that fact
			and generate just the one "column" reference (P.FIRST_NAME) in the SELECT clause.  Each attribute
			understands where to get that underlying JDBC value positionally.
		*** accessed only once per row - all of the JDBC ResultSet values are read just a single time and then
			held in a "current JDBC values array" as part of processing state via position - much more efficient.
			AttributeConverters et.al are applied at this step.


A "hopeful" goal was to centralize the generation of SQL into a single, consistent "engine" and a single, consistent handling
of results.

The main parts of the overall design for this work follow...


=== SQL AST

The decision was made to base this centralization for generating SQL, executing it and, for SELECTs, processing
its results on the idea of an Abstract Syntax Tree (AST) - which is just a fancy way of saying that we created
a visitable object representation of a SQL query (`org.hibernate.sql.ast.tree`) and contracts to:

	* produce such a tree (`org.hibernate.sql.produce`)
	* consume (walk) such a tree (`org.hibernate.sql.consume`)

Consumption of an SQL AST tree involves:

	* generating JDBC "operation" - `org.hibernate.sql.ast.tree.spi.Statement` and `org.hibernate.sql.ast.consume.spi.JdbcOperation`
	* executing these JDBC operation
	 	** CALL -> todo (6.0) (although `org.hibernate.sql.ast.consume.spi.JdbcCall` is done)
		** SELECT -> `org.hibernate.sql.ast.consume.spi.JdbcSelectExecutor`
		** DELETE -> todo (6.0)
		** UPDATE -> todo (6.0)
		** INSERT -> todo (6.0)
	* for operations returning results, processing ResultSet(s) into domain results - `org.hibernate.sql.exec.results`


Producing the SQL AST tree comes from 2 main sources:

	* Queries - HQL and Criteria, as well as custom "SQM producers"
	* Persister-based load, remove, etc calls.


In either case, persisters are responsible for generating the various SQL AST sub-trees such as its contributions
to a QuerySpec's FROM clause, SELECT clause, etc.  It was decided to have persisters directly produce SQL AST trees
in handling _Persister-based load, remove, etc calls_ because:

 	* It already knows how to generate the sub-trees.
 	* Is more performant than generation the SQM view and then walking that SQM.

The SQL AST tree is made up of the following parts...


==== FromClause - Tables and Groups and Spaces (oh my)

Modeling the from-clause is central to SQL (and to SQM as we will see later).  The FromClause (`org.hibernate.sql.ast.tree.spi.from.FromClause`)
is logically contained on a QuerySpec (`org.hibernate.sql.ast.tree.spi.QuerySpec`) meant to capture the commonality between
a top-level select and a sub-query select.  The FromClause is made up of the following parts, bottom-up:

TableReference:: `org.hibernate.sql.ast.tree.spi.from.TableReference` - Models a single Table
(`org.hibernate.persister.common.spi.Table`) reference.

TableGroup:: `org.hibernate.sql.ast.tree.spi.from.TableGroup` - Represents a related group of TableReference instances,
generally grouped by a common Navigable reference.  E.g. The EntityTableGroup includes TableReferences for all of the
Tables that the entity is mapped to.

TableGroupJoin:: Represents a joined TableGroup along with the target of join and any predicate.
used to represent joins between joinable Navigables.

TableSpace:: Models what ANSI SQL calls a "table reference".  Easiest way to think of this is the comma separated groups
of "from elements".  It is a grouping of a root TableGroup, and zero-or-more TableGroupJoin instances

FromClause:: grouping of one or more TableSpaces.

Let's look at some examples to make this more clear.  Along the way we will also look at the various contracts used
to build these TableGroups and TableGroupJoins...

[source]
.select e from Entity e (single table)
----
FromClause
    TableSpace
        rootTableGroup=EntityTableGroup(com.acme.Entity, "e")
            rootTableReference=TableBinding(PhysicalTable("t_entity"), "e0")
            tableReferenceJoins={}
        tableGroupJoins={}
----

The generation of all `TableSpace#rootTableGroup` references are handled through the
`org.hibernate.persister.queryable.spi.RootTableGroupProducer` contract.  Here, e.g.,
we'd get that root `EntityTableGroup(com.acme.Entity, "e")` reference by calling
`EntityPersister(com.acme.Entity)#applyRootTableGroup`.


[source]
.select e from Entity e (root table + secondary table)
----
FromClause
    TableSpace
        rootTableGroup=EntityTableGroup(com.acme.Entity, "e")
            rootTableReference=TableReference(PhysicalTable("t_entity"), "e0")
            tableReferenceJoins={
                TableReferenceJoin
                    TableReference(PhysicalTable("t_entity_secondary"), "e1")
                    INNER
                    <join predicate>
            }
        tableGroupJoins={}
----

All the table references here are part of the root TableGroup, so they are built
via the same `EntityPersister(com.acme.Entity)#applyRootTableGroup` we saw above.


[source]
.select e from Entity e (joined inheritance)
----
FromClause
    TableSpace
        rootTableGroup=EntityTableGroup(com.acme.Entity, "e")
            rootTableReference=TableReference(PhysicalTable("t_entity"), "e0")
            tableReferenceJoins={
                TableReferenceJoin
                    TableReference(PhysicalTable("t_entity_secondary"), "e1")
                    INNER
                    <join predicate>
            }
        tableGroupJoins={}
----

Built from the same `EntityPersister(com.acme.Entity)#applyRootTableGroup`


[source]
.select e from Entity e, SecondEntity se
----
FromClause
    TableSpace
        rootTableGroup=EntityTableGroup(com.acme.Entity, "e")
            rootTableReference=TableReference(PhysicalTable("t_entity"), "e0")
            tableReferenceJoins={}
        tableGroupJoins={}
    TableSpace
        rootTableGroup=EntityTableGroup(com.acme.SecondEntity, "se")
            rootTableReference=TableReference(PhysicalTable("t_second_entity"), "se0")
            tableReferenceJoins={}
        tableGroupJoins={}
----

[source]
.select e from Entity e inner join SecondEntity se on ...
----
FromClause
    TableSpace
        rootTableGroup=EntityTableGroup(com.acme.Entity, "e")
            rootTableReference=TableReference(PhysicalTable("t_entity"), "e0")
            tableReferenceJoins={}
        tableGroupJoins={
            TableGroupJoin
                EntityTableGroup(com.acme.SecondEntity, "se")
		            rootTableReference=TableReference(PhysicalTable("t_second_entity"), "se0")
                    INNER
                    <join predicate>
        }
----


==== Expressions

Expressions are fundamental to building the other parts of the SQL AST.  Examples of `Expression` include:

	* reference to part of the domain model (attribute, etc)
	* aggregation (count, sum, min, max, etc)
	* arithmetic operation
	* function
	* literal
	* parameter
	* case statement
	* dynamic instantiation (although this one is special in that it can only be used in the SELECT clause)
	* etc




==== SelectClause

The SQL AST `org.hibernate.sql.ast.tree.spi.select.SelectClause` contains one or more
`org.hibernate.sql.ast.tree.spi.select.Selection` references.  A `Selection` is made up of
a specific `Expression` and an optional "result variable" (the term used in JPA for the alias
assigned to a selection).  A `Selection` is obtained from `Expression#getType` -> `ExpressableType#makeSelection`.

A `Selection` operates as a producer of `QueryResult` instances (`Selection#makeQueryResult`).

	todo (6.0) : ^^ note that an alternative option is to pass `QueryResultCreationContext` into the
		creation of `Selection` which could build then the `QueryResult` at any time as needed and cache the reference
		for access later.

These `QueryResult` references:

	. model the individual values in the overall domain query result
	. contibute to the resolution/creation of the various readers, assemblers and initializers.

Some specific sub-types include:

	* `QueryResultScalar` - scalar query result; e.g. a function call in the HQL or reference to a String-valued attribute
	* `QueryResultComposite` - composite/embeddable valued query result
	* `QueryResultEntity` - an entity valued query return
	* `QueryResultDynamicInstantiation` - a "constructor" query result.  only used through SQM -> SQL AST producer
	* `QueryResultCollection` - specialized query result used when loading plural attribute entries.

Generally speaking an `Expression` is its own `Selectable`.  What does that mean?  Most `Expression` impls
additionally implement `Selectable` and return itself (`this`) as its `Selectable`.  For example,
the `org.hibernate.sql.ast.tree.spi.expression.AvgFunction` (modelling an AVG aggregate function) implements
`Expression` and also implements `Selectable`; it's `Expression#getSelectable` by returning itself as the
`AvgFunction` already knows how to build its Return (for `Selectable#makeQueryResult`).  The main case where this
is not the case is `NavigableReferenceExpression`s; for these the `Selectable` is part of the `Navigable`
model (proposed, it is not yet this way).

Ultimately this `SelectClause` need to be converted into a SQL SELECT statement as well as
"readers" to read back values from the JDBC `ResultSet`.  This is the role of `SqlSelectAstToJdbcSelectConverter`:

	* Rendering SQL String - `SqlSelectAstToJdbcSelectConverter` overall works on the principle of visitation,
		specifically visiting the "nodes" of the SQL AST tree.  As the individual nodes dispatch themselves
		to the visitor we used the specific visitor methods to render the various expressions as SQL fragments
		into the in-flight `SqlSelectAstToJdbcSelectConverter#sqlBuffer`.





==== SqlSelectAstToJdbcSelectConverter

`SqlSelectAstToJdbcSelectConverter` implements the transformation of a SQL SELECT AST into
a representation of the "JDBC operation(s)" to perform.  The inputs into this process are:

	* `org.hibernate.sql.ast.produce.spi.SqlSelectPlan`, made up of
		* `org.hibernate.sql.ast.tree.spi.SelectStatement` - the SQL AST tree
		* the `List` of `Return` references describing the query results (at the domain level.  Note that
			these are gleaned from the SQL AST

`org.hibernate.sql.ast.consume.spi.JdbcSelect.
a `org.hibernate.sql.ast.consume.spi.JdbcSelect` which represents the actual
JDBC call.

The 2 main responsibilities of `SqlSelectAstToJdbcSelectConverter`:

	* Rendering the SQL String
	* Building "readers" used later to read back the JDBC result values.

The input to `SqlSelectAstToJdbcSelectConverter` which encapsulates:

	* `org.hibernate.sql.ast.produce.spi.SqlSelectPlan` which encapsulates:
		. the SQL AST tree `org.hibernate.sql.ast.tree.spi.SelectStatement`
        . the `List` of `Return` references describing the query results (at the domain level)
    * `org.hibernate.query.spi.QueryParameterBindings`

The output from `SqlSelectAstToJdbcSelectConverter` is a `org.hibernate.sql.ast.consume.spi.JdbcSelect` which
models all the information needed to create, prepare and execute a SELECT `PreparedStatement` and
process its results.  It encapsulates:

	* The SQL String
	* `List` of `JdbcParameterBinder`
	* `List` of `SqlSelection` references (see section on reading results)
	* `List` of `Return` references (see section on reading results)


=== Rendering SQL String



As it walks the AST it renders the SELECT portion


This is also where the collection of `SqlSelection` references occurs.


=== Building "readers"

There are numerous actors involved in reading back results.  They are all built by this process based
on the `List<Return>` from `JdbcSelect` as well as the `SqlSelection` references
associated with the selected Expression.  These `SqlSelection`s are used to later read back the JDBC
values via the `SqlSelectionReader SqlSelection#getSqlSelectionReader` method.  The process for reading
results is covered later.

[IMPORTANT]
====
The process used to resolve the `SqlSelection` references given the `SqlSelectable` counterpart is
handled through the `org.hibernate.sql.ast.produce.result.spi.QueryResultCreationContext` contract
which `SqlSelectAstToJdbcSelectConverter` implements[1].  `SqlSelection` is the way we implement
positional access to the JDBC `ReultSet`.  `SqlSelection` maintains the position at which the SQL
selection was rendered and is the way we implement positional access to the JDBC `ResultSet` values.


This process is also used to "unique" the `SqlSelection` references per `SqlSelectable`.  The purpose of
this isto make sure we use the same `SqlSelection` for the same `SqlSelectable`
no matter how many times we see it.  E.g., multiple references to the `ColumnReference` `p.name`
will all resolve the the same `SqlSelection`.  In other words, given an HQL query like
`select p.name, p.name from Person p` we will actually render the following SQL:
`select p.name from person p`.  Notice the single column reference.  The HQL query will still
return the 2 values; we will see how that works when we talk about Return objects.

Combined with the positional access into the `ResultSet` this not only makes the JDBC value
reading more performant, it also makes the SQL shorter which is better for wire transfer as well
as DB query parsing.


[1] See `QueryResultCreationContext#resolveSqlSelection`
====



[NOTE]
====
todo (6.0) : ^^ cover "intermediary" raw JDBC values array and how things move into it and are then accessed.

todo (6.0) : ? - rename `Return` as `QueryResult` along with all related names?

todo (6.0) : I'd like to come back and investigate leveraging the SqlSelection position when rendering order-by (and group-by?) clauses.
ANSI SQL defines (and most DBs support) referring to a selection by position in the order-by.  For example, given a SQL
query like `select p.id, p.name from Person p order by 1`, the interpretation would be to order the
results by the first selection item (p.id).
====






-- end of work ---
rest needs to be re-worked











==== Parameters

There are multiple "parts" to parameter handling...

===== ParameterSpec

A ParameterSpec is the specification of a query parameter (name/position, target, etc).  It represents the
expectation(s) after parsing a query string.

Consider:

[source]
----
Query q = session.createQuery( "select p from Person p where p.name = :name" );
----

At this point the (Named)ParameterSpec for `":name"` has been parsed.   ParameterSpec allows for scenarios where the
SQM parser was able to ascertain an "anticipatedType" for the parameters.  Here, because `Person#name` is a `StringType`
we would anticipate `":name"` to also be a `StringType`; we will see later that ParameterBinding can adjust that.

It may also be a good idea to allow for a ParameterSpec to specify a requiredType.  This would accomodate
cases where the placement of the parameter in the query requires a certain Type to used.

Proposed ParameterSpec contract:

[source]
----
interface ParameterSpec {
    String getName();
    Integer getPosition();
    Type getAnticipatedType();
    Type getRequiredType();
}
----


===== ParameterBinding

ParameterBinding is the binding for a parameter.  Defined another way, it represents the value
specified by the user for the parameter for this execution of the query.

It can be thought of as the combination of a ParameterSpec, the specified value as well as some
additional specifics like Type, TemporalType handling, etc.

This part comes from the user.  Consider:

[source]
----
Query q = session.createQuery( "from Person p where p.name = :name" );
query.setParameter( "name", "Billy" );
----

Here, the `#setParameter` call creates the ParameterBinding.  This form would
"pick up" the anticipated-Type from the ParameterSpec.  We'd also allow
specifying the Type to use.

I think we should limit the overloaded form of this.  I can see the following options (using
named parameters for illustration):

[source]
----
interface Query {
    ...

    ParameterSpec getParameterSpec(String name);

    // returning this to keep API as before...

    Query setParameter(String name, Object value);
    Query setParameter(String name, Object value, Type target);
    Query setParameter(String name, Date value, TemporalType temporalType);
    Query setParameter(String name, Calendar value, TemporalType temporalType);
}
----


Proposed ParameterBinding contract:

[source]
----
interface ParameterBinding {
    ParameterSpec getParameterSpec();

    Object getValue();

    Type getType();
    TemporalType getTemporalType();
}
----


===== ParameterBinder

This is more of an esoteric concept at this point, but ultimately the idea is the binding of the
parameter value to JDBC.  It would be best to drive the binding of parameter values from "nodes
embedded in the query AST".  This could be a case where the implementation of ParameterSpec
additionally implements this "binding contract" as well.




=== Return (and Fetch)

The List of Return objects on SqmSelectInterpretation represent the Object-level returns for
the query.  Each Return in that List represents a single element in the naked Query's `Object[]` result "rows".

Some `Return` implementations also implement `FetchParent` meaning that they can contain `Fetch` references.

We will see these Return structures when we discuss reading results.

There are a number of concrete Return implementations representing the types of things
that can be a return in the query result:

`ReturnScalar`:: a Return tha is a scalar value (anything representable as a BasicType)
`ReturnComposite`:: a Return that is a composite/embeddable
`ReturnEntity`:: a Return that is an entity
`ReturnDynamicInstantiation`:: a Return that is a dyamic-instantiation
`ReturnCollection`:: a Return that is a collection.  *This is only valid for collection-loaders.*

Additionally, the following contracts are important:

`CollectionReference`:: defines a reference to a collection as either a `ReturnCollection` or `FetchCollectionAttribute`.
`EntityReference`:: defines a reference to an entity as either a `ReturnEntity` or `FetchEntityAttribute`.
`CompositeReference`:: todo : add this..



== 2nd phase - `org.hibernate.sql.ast.consume.spi.SqlSelectAstToJdbcSelectConverter` ->

`SqlAstInterpreter` takes as its input the SqmSelectInterpretation (and some other things)
and does a number of things and is responsible for mainly 2 tasks:

* Rendering the SQL String
* Building "readers"


=== Rendering SQL String

One of the functions performed by SqlAstInterpreter is to render the SQL AST into a SQL query String.  It
does this by walking the nodes of the SelectQuery using the visitation pattern.  Nothing to see here, move
along... :)


=== Building "readers"

There are numerous actors involved in reading back results.  They are all built by this process based
on the `List<Return>` from `SqmSelectInterpretation` as well as the `SqlSelection` references
associated with the selected Expression.

This will be discussed more in the section describing processing results.


== Processing results

There are quite a few actors involved in processing results and assembling the query returns.

First it is important to understand a major paradigm change in how JDBC results are obtained
in current Hibernate versions versus this PoC.

Previously all Types worked on the ResultSet directly.  To read a value from a ResultSet we'd ask the
type of assemble/resolve it (or nullSafeGet).  This has a major drawback in that we cannot hydrate
results from query-cache or ResultSet using the same code.

The design here is to abstract the actual source of "JDBC values" as `JdbcValuesSource`.  There
are 2 implementations of `JdbcValuesSource`:

* JdbcValuesSourceResultSetImpl - implements the JdbcValuesSource contract in terms of extracting
	those values from a JDBC ResultSet
* JdbcValuesSourceCacheHit - implements the JdbcValuesSource contract in terms of values found in the
	query cache

The main premise of `JdbcValuesSource` is to expose access to the values as a simple `Object[]` row.
This is where `SqlSelection` comes back into the picture.  We already discussed how `SqlSelection` knows
its position in the "JDBC result".  It also gives access to a `SqlSelectionReader` (via its `SqlSelectable`)
that we can use to read values from the JDBC ResultSet (as part of JdbcValuesSourceResultSetImpl).  At
this level of reading we are always dealing with simple basic types (single-column BasicType).  Conceptually
think of the row in the JDBC ResultSet as a Object[] of its extracted values.  This `Object[]` is exposed
from the `JdbcValuesSource` and ultimately exposed as `RowProcessingStateStandard#getJdbcValues` for higher-
level readers to access.


[IMPORTANT]
====
It is important to grok the flow of values to/from the query cache.  This handling individual
`Object[]` rows makes that seamless.  We've already seen the "from" aspect with `JdbcValuesSourceCacheHit`.
There is also a "to" component abstracted as `QueryCachePutManager`.  Again, this is all handled
seamlessly behind the scenes via `JdbcValuesSource` and `RowProcessingState`.
====

Certain Returns (and all Fetches) require some additional work to get the value ready to be a proper
object query return.  This is the role of `Initializer` impls.  I wont get too in depth in these as they
are still under active dev/design.  But they hearken back to load-plan work as well, so the initial
work here follows the lead of the load-plan initializers.

Finally a ReturnAssembler is responsible for assembling the actual Object to be put in the Query result
for a given Return.



== Open Design Questions

Collection of open questions regarding various aspects of the design of this work.


=== Better naming for the various representations of AttributeConverter

As of the latest work on wip/6.0 we currently we have the following:

org.hibernate.cfg.AttributeConverterDefinition::
[source]
----
/*
 * Representation of an {@link AttributeConverter} from externalized sources.  Generally
 * speaking these are contributed from:<ul>
 *     <li>converters discovered via {@link Converter} discovery</li>
 *     <li>application / integration contributions - {@link org.hibernate.boot.MetadataBuilder#applyAttributeConverter}</li>
 * </ul>
 * <p/>
 * Regardless of how they are known, the set of AttributeConverterDefinition instances
 * as known to {@link org.hibernate.boot.spi.MetadataBuildingOptions#getAttributeConverters()}
 * represents the complete set of "a priori converters".  After that point the only additional
 * converters recognized would come from local {@link javax.persistence.Convert} annotations.
 */
----

org.hibernate.target.converter.spi.AttributeConverterDefinition::
[source]
----
/*
 * Internal descriptor for an AttributeConverter implementation, with the intent of being
 * incorporated into a {@link org.hibernate.target.spi.BasicType}
 */
----

So essentially the same information as `org.hibernate.cfg.AttributeConverterDefinition` but with a
a slight different intent of being incorporated int o the BasicType

org.hibernate.boot.spi.AttributeConverterDescriptor::
[source]
----
/**
 * Internal descriptor for an AttributeConverter implementation.
 */
----

Is created from a `org.hibernate.cfg.AttributeConverterDefinition` or directly from a
	`javax.persistence.AttributeConverter` instance.  Used to determine auto-application


=== Consider adding Return/Fetch graph as part of SQM

or easily buildable from SQM.  The purpose would be determination of of the cacheability of
the query-plan for a given SQM.

This could also facilitate caching query-plans in cases where a load/fetch EntityGraph was specified
assuming the EntityGraph was applied to this SQM "return/fetch graph".  At the moment the presence of a
fetch graph excludes the query-plan from bing cached.

This comes down to a general decision of where the tipping point is for the effectiveness of caching
these plans (size of cache versus resources to build plan).

?Maybe config options stating what to to include in the cache key versus what implicitly means excluding from cache?








== 1st Phase - SqmSelectToSqlAstConverter

SqmSelectToSqlAstConverter takes in a SQM query (and a few other things) and produces a `SqmSelectInterpretation`.
The `SqmSelectInterpretation` encapsulates:

* The SQL AST (syntax tree) - SelectQuery
* a List of Return objects

The SQL AST as produced by SqmSelectToSqlAstConverter is a logic SQL representation.  It has
no Dialect specific handling.  It is still to-be-determined how to best allow Dialect specific hooks.

The sections below describe these 2 pieces of SqmSelectInterpretation information.

It is also important to note that SqmSelectToSqlAstConverter is responsible for applying
an EntityGraph hint (if supplied).  It is part of



See the section below
question - does SQM incorporate entity-graphs?  seems better to have the thing that interprets SQM to apply
entity-graphs.

question - better for persister to incorporate the model descriptor?  Or for persister to simply hold
reference to model descriptor?  The latter seems best (certainly least disruptive), however that makes querying
MappedSuperclasses more difficult.  This really comes down to a decision of whether to model MappedSuperclass
in the EntityPersister hierarchy.  As a follow-on to this... we should incorporate a representation of
MappedSuperclass into the SQM domain model.  Seems that the spec does not allow querying MappedSuperclasses; verify!


=== SQL AST

The SQL AST is a syntax tree modelling a SQL query.  It is made up of the following parts.
